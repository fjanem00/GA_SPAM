{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "# Library to be able to use bow\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# library to be able to use gnb\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.externals import joblib\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversor a formato de lectura del DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-987d910e1ab4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_frame_convert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"4K_dataset_enron.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maddress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_frame_convert\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name_File'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcsv_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./enronText2.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data_frame_convert = pd.read_csv(\"4K_dataset_enron.csv\")\n",
    "address = data_frame_convert['Name_File']\n",
    "csv_file = \"./enronText.csv\"\n",
    "\n",
    "with open(csv_file,'a') as writer:\n",
    "    h = \"Name,Category,Text\"\n",
    "    writer.write(h)\n",
    "    writer.write('\\n')\n",
    "                \n",
    "for file in address:\n",
    "    cat = data_frame_convert[data_frame_convert['Name_File']==file]['Category'].iloc[0]\n",
    "    if cat == 1:\n",
    "        path_spam = \"./spam/\"+file+\".txt\"\n",
    "        if os.path.isfile(path_spam):\n",
    "            \n",
    "            with open(path_spam, 'r',encoding='utf-8',errors='ignore') as txt_spam:\n",
    "                text_spam = str(txt_spam.read()).replace('\\n','').replace(',','')\n",
    "            with open(csv_file,'a') as writer:\n",
    "                    h = file+\",\"+str(cat)+\",\"+text_spam \n",
    "                    writer.writelines(h)\n",
    "                    writer.write('\\n')\n",
    "    \n",
    "    else:\n",
    "        path_ham = \"./ham/\"+file+\".txt\"\n",
    "        if os.path.isfile(path_ham):\n",
    "            \n",
    "            with open(path_ham, 'r') as txt:\n",
    "                text_ham = str(txt.read()).replace('\\n', '').replace(',','')\n",
    "            with open(csv_file,'a') as writer:\n",
    "                    h = file+\",\"+str(cat)+\",\"+text_ham\n",
    "                    writer.writelines(h)\n",
    "                    writer.write('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline predict original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tags = ['Ham','Spam']\n",
    "def predict_pipeline_OVA(pipeline, X_test, y_test):\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_test = lb.inverse_transform(y_test)\n",
    "    my_tags = pipeline.classes_\n",
    "\n",
    "    evaluate_prediction(y_pred, y_test)\n",
    "    precision_recall_f1(y_test, y_pred)\n",
    "    \n",
    "def evaluate_prediction(predictions, target, title=\"Confusion matrix\"):\n",
    "    print('accuracy %s' % accuracy_score(target, predictions))\n",
    "    print(\n",
    "        'Correctly Classifed {0} out of {1}'.format(accuracy_score(target, predictions, normalize=False), len(target)))\n",
    "    cm = confusion_matrix(target, predictions)\n",
    "    print('confusion matrix\\n %s' % cm)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plot_confusion_matrix(cm_normalized, title + ' Normalized')\n",
    "    print('(row=expected, col=predicted)')\n",
    "    \n",
    "    # count = 0\n",
    "    false_predict = predictions == target\n",
    "    paste_id = test_data['Name'].tolist()\n",
    "   \n",
    "    for idx, i in enumerate (false_predict):\n",
    "        \n",
    "        if i == False:\n",
    "            print(paste_id[idx], target[idx], predictions[idx])\n",
    "\n",
    "def precision_recall_f1(y_test, y_pred):\n",
    "    print('\\nmacro')\n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true=y_test, y_pred=y_pred, average='macro')\n",
    "    print('Precision: {0:0.3f}, Recall : {1:0.3f}, F1: {2:0.4f}'.format(p, r, f))\n",
    "\n",
    "    print('\\nmicro')\n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true=y_test, y_pred=y_pred, average='micro')\n",
    "    print('Precision: {0:0.3f}, Recall : {1:0.3f}, F1: {2:0.4f}'.format(p, r, f))\n",
    "\n",
    "    print('\\nweighted')\n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "    print('Precision: {0:0.3f}, Recall : {1:0.3f}, F1: {2:0.4f}'.format(p, r, f))\n",
    "\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "    accuracy = np.average(recall)\n",
    "    \n",
    "    print('\\nprecision: {}'.format(precision))\n",
    "    print('\\nrecall: {}'.format(recall))\n",
    "    print('\\nfscore: {}'.format(fscore))\n",
    "    print('\\nsupport: {}'.format(support))\n",
    "    print('\\nACC:{}'.format(accuracy))\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(my_tags))    \n",
    "    target_names = my_tags\n",
    "    plt.xticks(tick_marks, target_names, rotation=90)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def save_classifer(obj, obj_name):\n",
    "    pickle.dump(obj, open(obj_name, 'wb'))\n",
    "\n",
    "\n",
    "def load_classifier(obj_name):\n",
    "    return pickle.load(open(obj_name, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"enronText.csv\")\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "train_data, test_data = train_test_split(data_frame, test_size=.3, random_state=9)\n",
    "    \n",
    "X = data_frame['Text'].astype(str)\n",
    "y = data_frame['Category'].astype(str)\n",
    "y_frame_binary = lb.fit_transform(data_frame['Category'].astype(str))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_frame_binary, test_size=.3, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_lr_builder(train_data):\n",
    "\n",
    "    vectorizer = TfidfVectorizer(min_df=3, max_features=2945, norm='l2',\n",
    "                                 use_idf=True, smooth_idf=True, ngram_range=([1, 1]))\n",
    "    clf = linear_model.LogisticRegression( penalty='l2', C=50,random_state=0)\n",
    "    tfidf_lr_clf = Pipeline([('vect', vectorizer), ('clf', clf)])\n",
    "    tfidf_lr_clf = tfidf_lr_clf.fit(train_data['Text'].astype(str), train_data['Category'].astype(str))\n",
    "    return tfidf_lr_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_chi_lr_builder(train_data):\n",
    "    \n",
    "    \n",
    "    vectorizer = TfidfVectorizer(min_df= 3, stop_words=\"english\", sublinear_tf=True, norm='l2', ngram_range=(1, 2))\n",
    "    features = vectorizer.fit_transform(train_data['Text'])\n",
    "\n",
    "    chi2_features = chi2(features, train_data['Category']) \n",
    "    umbral = chi2_features[1] > 0.85\n",
    "    count = 0\n",
    "    final_features = features\n",
    "    for i, item in enumerate(umbral):\n",
    "        if item:\n",
    "            count = count + 1   \n",
    "    chi2_selector = SelectKBest(chi2, k=count)\n",
    "    clf = linear_model.LogisticRegression( penalty='l2', C=50,random_state=0)\n",
    "    tfidf_lr_clf = Pipeline([('vect', chi2_selector), ('clf', clf)])\n",
    "    tfidf_lr_clf = tfidf_lr_clf.fit(features, train_data['Category'].astype(str))\n",
    "    return tfidf_lr_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tfidf_lr_clf = tfidf_chi_lr_builder(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tags = ['Ham','Spam']\n",
    "def predict_pipeline_OVA(pipeline, X_test, y_test):\n",
    "    \n",
    "    #vectorizer = TfidfVectorizer(min_df= 3, stop_words=\"english\", sublinear_tf=True, norm='l2', ngram_range=(1, 2))\n",
    "    #features_test = vectorizer.fit_transform(X_test)\n",
    "    \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_test = lb.inverse_transform(y_test)\n",
    "    my_tags = pipeline.classes_\n",
    "    evaluate_prediction(y_pred, y_test)\n",
    "    precision_recall_f1(y_test, y_pred)\n",
    "    \n",
    "def evaluate_prediction(predictions, target, title=\"Confusion matrix\"):\n",
    "    print('accuracy %s' % accuracy_score(target, predictions))\n",
    "    print(\n",
    "        'Correctly Classifed {0} out of {1}'.format(accuracy_score(target, predictions, normalize=False), len(target)))\n",
    "    cm = confusion_matrix(target, predictions)\n",
    "    print('confusion matrix\\n %s' % cm)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plot_confusion_matrix(cm_normalized, title + ' Normalized')\n",
    "    print('(row=expected, col=predicted)')\n",
    "    \n",
    "    # count = 0\n",
    "    false_predict = predictions == target\n",
    "    paste_id = test_data['Name'].tolist()\n",
    "   \n",
    "    for idx, i in enumerate (false_predict):\n",
    "        \n",
    "        if i == False:\n",
    "            print(paste_id[idx], target[idx], predictions[idx])\n",
    "\n",
    "def precision_recall_f1(y_test, y_pred):\n",
    "    print('\\nmacro')\n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true=y_test, y_pred=y_pred, average='macro')\n",
    "    print('Precision: {0:0.3f}, Recall : {1:0.3f}, F1: {2:0.4f}'.format(p, r, f))\n",
    "\n",
    "    print('\\nmicro')\n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true=y_test, y_pred=y_pred, average='micro')\n",
    "    print('Precision: {0:0.3f}, Recall : {1:0.3f}, F1: {2:0.4f}'.format(p, r, f))\n",
    "\n",
    "    print('\\nweighted')\n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "    print('Precision: {0:0.3f}, Recall : {1:0.3f}, F1: {2:0.4f}'.format(p, r, f))\n",
    "\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "    accuracy = np.average(recall)\n",
    "    \n",
    "    print('\\nprecision: {}'.format(precision))\n",
    "    print('\\nrecall: {}'.format(recall))\n",
    "    print('\\nfscore: {}'.format(fscore))\n",
    "    print('\\nsupport: {}'.format(support))\n",
    "    print('\\nACC:{}'.format(accuracy))\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(my_tags))    \n",
    "    target_names = my_tags\n",
    "    plt.xticks(tick_marks, target_names, rotation=90)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def save_classifer(obj, obj_name):\n",
    "    pickle.dump(obj, open(obj_name, 'wb'))\n",
    "\n",
    "\n",
    "def load_classifier(obj_name):\n",
    "    return pickle.load(open(obj_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Subject: re : may wellhead \" spot \" purchases - requestvance as we discussed yesterday  i will zero the confirmed column in pops for barrett and increase the same for seneca .bobfrom : vance l taylor / enron @ enronxgate on 04 / 26 / 2001 11 : 42 amto : robert cotten / hou / ect @ ectcc : george weissman / hou / ect @ ect  daren j farmer / hou / ect @ enron  melissa graves / enron @ enronxgate  susan smith / hou / ect @ enronsubject : re : may wellhead \" spot \" purchases - requestbob i \\' m still concern about april \\' s nom ; if we don \\' t take it to zero  than we could have the possibility of the allocations group adding volumes to barrett \\' s april deal . this would be incorrect .vlt- - - - - original message - - - - -from : cotten  robertsent : thursday  april 26  2001 9 : 27 amto : taylor  vance l .cc : weissman  george ; daren j farmer / hou / ect @ enron ; graves  melissa ; susan smith / hou / ect @ enronsubject : re : may wellhead \" spot \" purchases - requestvance based on the information below  nominations are being revised effective may 1  2001 :counterparty meter # orig . nom rev . nombarrett resources 0435 1  536 0seneca resources 0435 3  073 4  609total 4  609 4  609bobfrom : vance l taylor / enron @ enronxgate on 04 / 25 / 2001 08 : 42 amto : robert cotten / hou / ect @ ectcc : george weissman / hou / ect @ ect  susan smith / enron @ enronxgate  melissa graves / enron @ enronxgatesubject : re : may wellhead \" spot \" purchases - requestbob hplc continues to purchase gas from both ocean and seneca on a term basis ; firm tickets were submitted for april origination beginning with the month of april . as for as barrett  they are selling their gas under a joa with seneca ; therefore  100 % of barrett \\' s production is being paid to seneca . consequently  you should see tickets in sitara for both counterparties .let me know is you can \\' t .vltx 36353- - - - - original message - - - - -from : cotten  robertsent : tuesday  april 24  2001 6 : 20 pmto : taylor  vance l .cc : weissman  georgesubject : re : may wellhead \" spot \" purchases - requestvance are we still purchasing gas at meter 435 from barrett resources  ocean energy and seneca resources ? they were on george \\' s spreadsheet but they are not termed up . the only deals termed up are mariner  st . mary land  walter oil & gas and the meridian resource .bobfrom : vance l taylor / enron @ enronxgate on 04 / 24 / 2001 04 : 25 pmto : robert cotten / hou / ect @ ectcc : janie aguayo / hou / ect @ ect  lisa hesse / hou / ect @ ect  julie meyers / hou / ect @ ect  cynthia hakemack / hou / ect @ ect  donald p reinhardt / enron @ enronxgate  susan smith / enron @ enronxgate  melissa graves / enron @ enronxgate  george weissman / hou / ect @ ectsubject : may wellhead \" spot \" purchases - requestbob hplc will be purchasing wellhead gas from the producers listed below for the production month of may  2001 . this production will be purchased on a \" spot \" basis and deal tickets should be created and entered into sitara based on the following information :counterparty meter volume priceapache corporation 0435 1409 mmbtu / d 100 % if / hsc less $ 0 . 10whiting petroleum corp 6523 113 mmbtu / d 85 % if / hscel paso merchant energy  lp 5923 622 mmbtu / d 100 % if / hsc less $ 0 . 26el paso merchant energy  lp 5848 203 mmbtu / d 85 % if / hsc swift energy 2630 21 mmbtu / d 100 % if / hsc less $ 1 . 38duke energy trading & marketing 6347 147 mmbtu / d 85 % if / hschesco gathering oil co . 6063 289 mmbtu / d 85 % if / hscembassy natural gas inc . 6598 lmmbtu / d 85 % if / hscstone energy 9696 2745 mmbtu / d 100 % if / hsc less $ 0 . 20the houston exploration 9696 3407 mmbtu / d 100 % if / hsc less $ 0 . 20amerada hess ( hess energy svcs ) 0435 1104 mmbtu / d 100 % if / hsc less $ 0 . 14crosstex energy services  ltd . 0435 656 mmbtu / d 100 % if / hsc less $ 0 . 12tri - union development 0435 149 mmbtu / d 100 % if / hsc less $ 0 . 055ranger oil company 9871 200 mmbtu / d 85 % if / hsc if 300 / dthese are producer svcs . deals and should be tracked in the im wellhead portfolio . . . attached to the gathering contract .additionally  if at all possible  please do not confirm the apache and crosstex deals as we expect to receive term firm contracts in the very near future .thanks vltx 3 - 6353'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-2cee830b470f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_pipeline_OVA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_lr_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-131-8117c48b7429>\u001b[0m in \u001b[0;36mpredict_pipeline_OVA\u001b[0;34m(pipeline, X_test, y_test)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#features_test = vectorizer.fit_transform(X_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmy_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    255\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'M8[ns]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/arrays/numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Subject: re : may wellhead \" spot \" purchases - requestvance as we discussed yesterday  i will zero the confirmed column in pops for barrett and increase the same for seneca .bobfrom : vance l taylor / enron @ enronxgate on 04 / 26 / 2001 11 : 42 amto : robert cotten / hou / ect @ ectcc : george weissman / hou / ect @ ect  daren j farmer / hou / ect @ enron  melissa graves / enron @ enronxgate  susan smith / hou / ect @ enronsubject : re : may wellhead \" spot \" purchases - requestbob i \\' m still concern about april \\' s nom ; if we don \\' t take it to zero  than we could have the possibility of the allocations group adding volumes to barrett \\' s april deal . this would be incorrect .vlt- - - - - original message - - - - -from : cotten  robertsent : thursday  april 26  2001 9 : 27 amto : taylor  vance l .cc : weissman  george ; daren j farmer / hou / ect @ enron ; graves  melissa ; susan smith / hou / ect @ enronsubject : re : may wellhead \" spot \" purchases - requestvance based on the information below  nominations are being revised effective may 1  2001 :counterparty meter # orig . nom rev . nombarrett resources 0435 1  536 0seneca resources 0435 3  073 4  609total 4  609 4  609bobfrom : vance l taylor / enron @ enronxgate on 04 / 25 / 2001 08 : 42 amto : robert cotten / hou / ect @ ectcc : george weissman / hou / ect @ ect  susan smith / enron @ enronxgate  melissa graves / enron @ enronxgatesubject : re : may wellhead \" spot \" purchases - requestbob hplc continues to purchase gas from both ocean and seneca on a term basis ; firm tickets were submitted for april origination beginning with the month of april . as for as barrett  they are selling their gas under a joa with seneca ; therefore  100 % of barrett \\' s production is being paid to seneca . consequently  you should see tickets in sitara for both counterparties .let me know is you can \\' t .vltx 36353- - - - - original message - - - - -from : cotten  robertsent : tuesday  april 24  2001 6 : 20 pmto : taylor  vance l .cc : weissman  georgesubject : re : may wellhead \" spot \" purchases - requestvance are we still purchasing gas at meter 435 from barrett resources  ocean energy and seneca resources ? they were on george \\' s spreadsheet but they are not termed up . the only deals termed up are mariner  st . mary land  walter oil & gas and the meridian resource .bobfrom : vance l taylor / enron @ enronxgate on 04 / 24 / 2001 04 : 25 pmto : robert cotten / hou / ect @ ectcc : janie aguayo / hou / ect @ ect  lisa hesse / hou / ect @ ect  julie meyers / hou / ect @ ect  cynthia hakemack / hou / ect @ ect  donald p reinhardt / enron @ enronxgate  susan smith / enron @ enronxgate  melissa graves / enron @ enronxgate  george weissman / hou / ect @ ectsubject : may wellhead \" spot \" purchases - requestbob hplc will be purchasing wellhead gas from the producers listed below for the production month of may  2001 . this production will be purchased on a \" spot \" basis and deal tickets should be created and entered into sitara based on the following information :counterparty meter volume priceapache corporation 0435 1409 mmbtu / d 100 % if / hsc less $ 0 . 10whiting petroleum corp 6523 113 mmbtu / d 85 % if / hscel paso merchant energy  lp 5923 622 mmbtu / d 100 % if / hsc less $ 0 . 26el paso merchant energy  lp 5848 203 mmbtu / d 85 % if / hsc swift energy 2630 21 mmbtu / d 100 % if / hsc less $ 1 . 38duke energy trading & marketing 6347 147 mmbtu / d 85 % if / hschesco gathering oil co . 6063 289 mmbtu / d 85 % if / hscembassy natural gas inc . 6598 lmmbtu / d 85 % if / hscstone energy 9696 2745 mmbtu / d 100 % if / hsc less $ 0 . 20the houston exploration 9696 3407 mmbtu / d 100 % if / hsc less $ 0 . 20amerada hess ( hess energy svcs ) 0435 1104 mmbtu / d 100 % if / hsc less $ 0 . 14crosstex energy services  ltd . 0435 656 mmbtu / d 100 % if / hsc less $ 0 . 12tri - union development 0435 149 mmbtu / d 100 % if / hsc less $ 0 . 055ranger oil company 9871 200 mmbtu / d 85 % if / hsc if 300 / dthese are producer svcs . deals and should be tracked in the im wellhead portfolio . . . attached to the gathering contract .additionally  if at all possible  please do not confirm the apache and crosstex deals as we expect to receive term firm contracts in the very near future .thanks vltx 3 - 6353'"
     ]
    }
   ],
   "source": [
    "predict_pipeline_OVA(tfidf_lr_clf, test_data['Text'], test_data['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_classifer(tfidf_lr_clf, 'tfidf_lr_clf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
